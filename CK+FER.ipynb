{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CK+FER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xGYiBYj22h5FAywTkoB9YSEewLhABCkr",
      "authorship_tag": "ABX9TyO+YvQdMyn04Brq0i4ZNz3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoreKajal/Facial-Expression-Recognition-Using-Python-TensorFlow-2.0/blob/main/CK%2BFER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RAA2DlUxKoe"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\r\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\r\n",
        "# For example, here's several helpful packages to load in \r\n",
        "\r\n",
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import os,cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "from pylab import rcParams\r\n",
        "rcParams['figure.figsize'] = 20, 10\r\n",
        "\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import keras\r\n",
        "\r\n",
        "from keras.utils import np_utils\r\n",
        "# Input data files are available in the \"../input/\" directory.\r\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense , Activation , Dropout ,Flatten\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "from keras.layers.convolutional import MaxPooling2D\r\n",
        "from keras.metrics import categorical_accuracy\r\n",
        "from keras.models import model_from_json\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.optimizers import *\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "import os\r\n",
        "print(os.listdir(\"/content/drive/MyDrive/M.Tech Projects/Facial Expression Project/CK+ Kaggle/\"))\r\n",
        "\r\n",
        "\r\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZXX1d9x0kJH"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/M.Tech Projects/Facial Expression Project/CK+ Kaggle/CK+NewDataset'\r\n",
        "data_dir_list = os.listdir(data_path)\r\n",
        "\r\n",
        "img_rows=256\r\n",
        "img_cols=256\r\n",
        "num_channel=1\r\n",
        "\r\n",
        "num_epoch=10\r\n",
        "\r\n",
        "img_data_list=[]\r\n",
        "\r\n",
        "\r\n",
        "for dataset in data_dir_list:\r\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\r\n",
        "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\r\n",
        "    for img in img_list:\r\n",
        "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\r\n",
        "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\r\n",
        "        input_img_resize=cv2.resize(input_img,(48,48))\r\n",
        "        img_data_list.append(input_img_resize)\r\n",
        "        \r\n",
        "img_data = np.array(img_data_list)     #img arrays\r\n",
        "img_data = img_data.astype('float32')  #img arrays converted to float value arrays\r\n",
        "img_data = img_data/255                #Normalize the array\r\n",
        "img_data.shape\r\n",
        "print(\"What is the shape of img array created-->\", img_data.shape)\r\n",
        "#print(\"Whats here-->\", img_data.shape)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VFT06fb221A"
      },
      "source": [
        "num_classes = 7\r\n",
        "\r\n",
        "num_of_samples = img_data.shape[0]\r\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\r\n",
        "\r\n",
        "labels[0:9]=0 #10\r\n",
        "labels[10:19]=1 #10\r\n",
        "labels[20:29]=2 #10\r\n",
        "labels[30:39]=3 #10\r\n",
        "labels[40:49]=4 #10\r\n",
        "labels[50:59]=5 #10\r\n",
        "labels[60:69]=6 #10\r\n",
        "\r\n",
        "names = ['anger','contempt','disgust','fear','happy','sadness','surprise']\r\n",
        "\r\n",
        "def getLabel(id):\r\n",
        "    return ['anger','contempt','disgust','fear','happy','sadness','surprise'][id]\r\n",
        "\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3aKlLn6EZb"
      },
      "source": [
        "Y = np_utils.to_categorical(labels, num_classes)\r\n",
        "\r\n",
        "#Shuffle the dataset\r\n",
        "x,y = shuffle(img_data,Y, random_state=2)\r\n",
        "# Split the dataset\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)\r\n",
        "x_test=X_test\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQNu9DFd6I4n"
      },
      "source": [
        "input_shape=(48,48,3)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation = 'relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(7, activation = 'softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aCXxOU16Zp4"
      },
      "source": [
        "model.summary()\r\n",
        "model.get_config()\r\n",
        "model.layers[0].get_config()\r\n",
        "model.layers[0].input_shape\r\n",
        "model.layers[0].output_shape\r\n",
        "model.layers[0].get_weights()\r\n",
        "np.shape(model.layers[0].get_weights()[0])\r\n",
        "model.layers[0].trainable\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQAVC82d6oLn"
      },
      "source": [
        "from keras import callbacks\r\n",
        "filename='model_train_new.csv'\r\n",
        "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\r\n",
        "\r\n",
        "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\r\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "callbacks_list = [csv_log,checkpoint]\r\n",
        "callbacks_list = [csv_log]\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP5kBh9M68wJ"
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=7, epochs=50, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeHIKTTd7AdA"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('Test Loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])\r\n",
        "\r\n",
        "test_image = X_test[0:1]\r\n",
        "print(\"Test img shape-->\", test_image.shape)\r\n",
        "\r\n",
        "print(\"model predict for test img-->\", model.predict(test_image))\r\n",
        "print(\"Predicted classes of test img-->\",model.predict_classes(test_image))\r\n",
        "print(\"Correlate with ids-->\",y_test[0:1])\r\n",
        "\r\n",
        "#res = model.predict_classes(X_test[9:18])   #For complete ck+ dataset\r\n",
        "res = model.predict_classes(X_test[0:9])\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "\r\n",
        "for i in range(0, 9):\r\n",
        "    plt.subplot(330 + 1 + i)\r\n",
        "    plt.imshow(x_test[i],cmap=plt.get_cmap('gray'))\r\n",
        "    plt.gca().get_xaxis().set_ticks([])\r\n",
        "    plt.gca().get_yaxis().set_ticks([])\r\n",
        "    plt.ylabel('prediction = %s' % getLabel(res[i]), fontsize=14)\r\n",
        "# show the plot\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvqEE7M2-dPc"
      },
      "source": [
        "# visualizing losses and accuracy\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "train_loss=hist.history['loss']\r\n",
        "val_loss=hist.history['val_loss']\r\n",
        "#train_acc=hist.history['acc']\r\n",
        "train_acc=hist.history['accuracy']\r\n",
        "#val_acc=hist.history['val_acc']\r\n",
        "val_acc=hist.history['val_accuracy']   # acc is renamed in TensorFlow 2.0\r\n",
        "\r\n",
        "epochs = range(len(train_acc))\r\n",
        "\r\n",
        "plt.plot(epochs,train_loss,'r', label='train_loss')\r\n",
        "plt.plot(epochs,val_loss,'b', label='val_loss')\r\n",
        "plt.title('train_loss vs val_loss')\r\n",
        "plt.legend()\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs,train_acc,'r', label='train_acc')\r\n",
        "plt.plot(epochs,val_acc,'b', label='val_acc')\r\n",
        "plt.title('train_acc vs val_acc')\r\n",
        "plt.legend()\r\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}